{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113155,"databundleVersionId":13473948,"sourceType":"competition"},{"sourceId":442871,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":359690,"modelId":380893}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\n \nfrom sklearn.linear_model import ElasticNet \nfrom sklearn.model_selection import KFold, GridSearchCV  \nfrom transformers import AutoModelForMaskedLM, AutoTokenizer, AutoModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:39:22.142601Z","iopub.execute_input":"2025-10-15T06:39:22.142957Z","iopub.status.idle":"2025-10-15T06:39:39.023239Z","shell.execute_reply.started":"2025-10-15T06:39:22.142929Z","shell.execute_reply":"2025-10-15T06:39:39.022236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/melting-point/train.csv')\nchemberta_model = '/kaggle/input/c/transformers/default/1/ChemBERTa-77M-MLM'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:39:39.025111Z","iopub.execute_input":"2025-10-15T06:39:39.025739Z","iopub.status.idle":"2025-10-15T06:39:39.187800Z","shell.execute_reply.started":"2025-10-15T06:39:39.025713Z","shell.execute_reply":"2025-10-15T06:39:39.186826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model retrieved from https://www.kaggle.com/code/michaelrowen/opp2025-chemberta-pre-trained-base\nclass BERTEmbedder:\n    def __init__(self, model_name):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name)\n        self.model.eval()\n\nprint('Loading ChemBERTa model...')\ntry:\n    chemberta = BERTEmbedder(model_name=chemberta_model)\n    print('ChemBERTa loaded successfully!')\nexcept Exception as e:\n    print(f'Error loading ChemBERTa: {e}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:39:39.188527Z","iopub.execute_input":"2025-10-15T06:39:39.188806Z","iopub.status.idle":"2025-10-15T06:40:04.009850Z","shell.execute_reply.started":"2025-10-15T06:39:39.188786Z","shell.execute_reply":"2025-10-15T06:40:04.008754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_chembert_embeddings(smiles_list, embedder, n_data):\n    n_latent = 384\n    embeddings = np.zeros((n_data, n_latent))\n    \n    for i, smiles in enumerate(smiles_list):\n        with torch.no_grad():\n            # Getting the model output\n            encoded_input = embedder.tokenizer(smiles, return_tensors='pt', padding=True, truncation=True)\n            model_output = embedder.model(**encoded_input)\n        \n            # Getting the CLS token from model output\n            embedding = model_output[0][:,0,:]\n            embeddings[i, :] = embedding.numpy()\n    \n    return pd.DataFrame(embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:04.010781Z","iopub.execute_input":"2025-10-15T06:40:04.011414Z","iopub.status.idle":"2025-10-15T06:40:04.017947Z","shell.execute_reply.started":"2025-10-15T06:40:04.011387Z","shell.execute_reply":"2025-10-15T06:40:04.016720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code retrieved from https://www.kaggle.com/code/michaelrowen/opp2025-chemberta-pre-trained-base\ndef extract_simple_molecular_features(smiles_list):\n    features = []\n    for smiles in smiles_list:\n        feature_vector = [\n            len(smiles),  # SMILES length\n            smiles.count('C'),  # Carbon count\n            smiles.count('N'),  # Nitrogen count\n            smiles.count('O'),  # Oxygen count\n            smiles.count('S'),  # Sulfur count\n            smiles.count('P'),  # Phosphorus count\n            smiles.count('F'),  # Fluorine count\n            smiles.count('Cl'),  # Chlorine count\n            smiles.count('Br'),  # Bromine count\n            smiles.count('I'),  # Iodine count\n            smiles.count('='),  # Double bonds\n            smiles.count('#'),  # Triple bonds\n            smiles.count('-'),  # Single bonds\n            smiles.count('(') + smiles.count(')'),  # Branching\n            smiles.count('[') + smiles.count(']'),  # Bracket atoms\n            smiles.count('@'),  # Chirality centers\n            smiles.count('c'),  # Aromatic carbon\n            smiles.count('n'),  # Aromatic nitrogen\n            smiles.count('o'),  # Aromatic oxygen\n            smiles.count('s'),  # Aromatic sulfur\n        ]\n        features.append(feature_vector)\n    \n    return pd.DataFrame(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:04.021560Z","iopub.execute_input":"2025-10-15T06:40:04.022095Z","iopub.status.idle":"2025-10-15T06:40:04.134189Z","shell.execute_reply.started":"2025-10-15T06:40:04.022056Z","shell.execute_reply":"2025-10-15T06:40:04.133109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings_train = extract_chembert_embeddings(df_train['SMILES'], chemberta, df_train.shape[0])\nmolecular_features_train = extract_simple_molecular_features(df_train['SMILES'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:04.135171Z","iopub.execute_input":"2025-10-15T06:40:04.135473Z","iopub.status.idle":"2025-10-15T06:40:17.596174Z","shell.execute_reply.started":"2025-10-15T06:40:04.135441Z","shell.execute_reply":"2025-10-15T06:40:17.595350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(embeddings_train.shape, type(embeddings_train))\nprint(molecular_features_train.shape, type(molecular_features_train))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:17.597053Z","iopub.execute_input":"2025-10-15T06:40:17.597355Z","iopub.status.idle":"2025-10-15T06:40:17.603094Z","shell.execute_reply.started":"2025-10-15T06:40:17.597330Z","shell.execute_reply":"2025-10-15T06:40:17.602372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_ttl = pd.concat([df_train, embeddings_train, molecular_features_train], axis=1)\ndf_ttl.drop(['id', 'SMILES'], axis=1, inplace=True)\ny_train = df_ttl['Tm']\nX_train = df_ttl.drop(['Tm'], axis=1)\nX_train.columns = [str(colname) for colname in X_train.columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:17.603956Z","iopub.execute_input":"2025-10-15T06:40:17.604261Z","iopub.status.idle":"2025-10-15T06:40:17.674846Z","shell.execute_reply.started":"2025-10-15T06:40:17.604240Z","shell.execute_reply":"2025-10-15T06:40:17.673952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 4\n\n# Initialize the classifier  \n#model = RandomForestRegressor(n_jobs=-1)\nmodel = ElasticNet()\n\n# Define hyperparameter grid for optimization  \nparam_grid = {\n    'alpha' : [0.1, 0.5, 1, 5, 50, 100, 200],\n    'l1_ratio': [0.25, 0.5, 0.75]\n}  \n\n# Set up cross-validation  \ncv = KFold(n_splits=10, shuffle=True, random_state=seed)  \n  \n# Set up GridSearchCV  \ngs = GridSearchCV(  \n    estimator=model,  \n    param_grid=param_grid,  \n    cv=cv,  \n    scoring='neg_mean_absolute_error',  \n    verbose=1,  \n    n_jobs=-1  \n)  \n  \n# Fit the model with categorical feature information  \ngs.fit(X_train, y_train)  \n  \n# Print the best hyperparameters and score  \nprint(\"Best hyperparameters:\", gs.best_params_)  \nprint(\"Best CV accuracy:\", gs.best_score_)  \n  \n# Get the best model  \nbest_model = gs.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:17.675633Z","iopub.execute_input":"2025-10-15T06:40:17.675953Z","iopub.status.idle":"2025-10-15T06:40:42.225396Z","shell.execute_reply.started":"2025-10-15T06:40:17.675927Z","shell.execute_reply":"2025-10-15T06:40:42.224645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:42.226043Z","iopub.execute_input":"2025-10-15T06:40:42.226286Z","iopub.status.idle":"2025-10-15T06:40:42.246836Z","shell.execute_reply.started":"2025-10-15T06:40:42.226264Z","shell.execute_reply":"2025-10-15T06:40:42.245978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/melting-point/test.csv')\nembeddings_test = extract_chembert_embeddings(df_test['SMILES'], chemberta, df_test.shape[0])\nmolecular_features_test = extract_simple_molecular_features(df_test['SMILES'])\n\ndf_ttl = pd.concat([df_test, embeddings_test, molecular_features_test], axis=1)\nX_test = df_ttl.drop(['id', 'SMILES'], axis=1)\nX_test.columns = [str(colname) for colname in X_test.columns]\n\ny_pred = best_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:42.247908Z","iopub.execute_input":"2025-10-15T06:40:42.249326Z","iopub.status.idle":"2025-10-15T06:40:45.604396Z","shell.execute_reply.started":"2025-10-15T06:40:42.249297Z","shell.execute_reply":"2025-10-15T06:40:45.603641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_out = pd.DataFrame({'id': df_ttl['id'],'Tm': y_pred})\ndf_out.to_csv('./submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:40:45.605365Z","iopub.execute_input":"2025-10-15T06:40:45.605714Z","iopub.status.idle":"2025-10-15T06:40:45.618404Z","shell.execute_reply.started":"2025-10-15T06:40:45.605668Z","shell.execute_reply":"2025-10-15T06:40:45.617444Z"}},"outputs":[],"execution_count":null}]}